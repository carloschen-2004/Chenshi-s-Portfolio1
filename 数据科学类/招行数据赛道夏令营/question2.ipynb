{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               # 数据处理和DataFrame操作\n",
    "import numpy as np                # 数值计算\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF特征提取\n",
    "from sklearn.decomposition import TruncatedSVD  # 降维处理\n",
    "from tqdm import tqdm             # 进度条显示\n",
    "import gc                         # 垃圾回收，内存管理\n",
    "import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import optimize\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: divide by zero encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: overflow encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/extmath.py:547: RuntimeWarning: invalid value encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "/var/folders/qp/1q3xfgbn6934vd2lg657fv740000gn/T/ipykernel_64474/1504018887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/keep-rational/Desktop/赛题2和3/train_text.csv')\n",
    "test = pd.read_csv('/Users/keep-rational/Desktop/赛题2和3/test_text.csv')\n",
    "test.columns = ['新闻ID','文本','标签']\n",
    "train['标签'] -= 1\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "\n",
    "#统计特征\n",
    "data['文本长度'] = data['文本'].apply(lambda x:len(x.split(' ')))\n",
    "\n",
    "#TF-IDF特征\n",
    "size_dict = {'文本':128}\n",
    "TfidfVectorizer_feats = []\n",
    "for i in tqdm.tqdm(['文本']):\n",
    "    # TF-IDF算法提取文本特征\n",
    "    tfidf = TfidfVectorizer(min_df=3,max_df=0.5,analyzer='word',ngram_range=(1,3))\n",
    "    tf = tfidf.fit_transform(data[i].values)\n",
    "\n",
    "    #使用SVD降维\n",
    "    decom = TruncatedSVD(n_components=size_dict[i],random_state=42)\n",
    "    decom_fea = pd.DataFrame(decom.fit_transform(tf))\n",
    "\n",
    "    #为新特征添加列名\n",
    "    decom_fea.columns = [i + f'_tfidf_{j}' for j in range(size_dict[i])]\n",
    "    TfidfVectorizer_feats += [i + f'_tfidf_{j}' for j in range(size_dict[i])]\n",
    "\n",
    "    #将降维后的数据添加到原数据集\n",
    "    data[[i + f'_tfidf_{j}' for j in range(size_dict[i])]] = decom_fea[[i + f'_tfidf_{j}' for j in range(size_dict[i])]].values\n",
    "\n",
    "    del decom_fea\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 Macro F1-Score: 0.72332\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 Macro F1-Score: 0.74851\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 Macro F1-Score: 0.74818\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 Macro F1-Score: 0.74602\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 Macro F1-Score: 0.73960\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.754858\n",
      "         Iterations: 3\n",
      "         Function evaluations: 310\n",
      "阈值优化前: 0.7414358124290727\n",
      "阈值优化后: 0.7548581862229895\n",
      "提交文件已生成: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 数据准备\n",
    "LABEL = '标签'\n",
    "feats = [f for f in data.columns if f not in [LABEL, '新闻ID', '文本']]\n",
    "df_train = data[~data[LABEL].isna()].copy()\n",
    "df_test = data[data[LABEL].isna()].copy()\n",
    "\n",
    "# 5折交叉验证\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# 存储每折的F1分数和预测结果\n",
    "scores = []\n",
    "oof = np.zeros((df_train.shape[0], 4))\n",
    "test_preds = np.zeros((df_test.shape[0], 4))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train[LABEL])):\n",
    "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "    X_train, X_val = df_train[feats].iloc[train_idx], df_train[feats].iloc[val_idx]\n",
    "    y_train, y_val = df_train[LABEL].iloc[train_idx], df_train[LABEL].iloc[val_idx]\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = LGBMClassifier(\n",
    "        objective='multiclass',\n",
    "        num_class=4,\n",
    "        boosting_type='gbdt',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # 模型训练\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 验证集预测\n",
    "    val_pred = model.predict_proba(X_val)\n",
    "    oof[val_idx] = val_pred\n",
    "    \n",
    "    # 计算F1-score(宏平均)\n",
    "    score = f1_score(y_val, val_pred.argmax(-1), average='macro')\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {fold + 1} Macro F1-Score: {score:.5f}\")\n",
    "    \n",
    "    # 测试集预测\n",
    "    test_preds += model.predict_proba(df_test[feats]) / n_splits\n",
    "\n",
    "# 阈值优化\n",
    "def fun(x):\n",
    "    tmp = []\n",
    "    for i in range(4):\n",
    "        tmp.append(x[i] * oof[:, i].reshape(-1, 1))\n",
    "    tmp = np.hstack(tmp)\n",
    "    return -f1_score(df_train[LABEL].values, np.argmax(tmp, axis=1), average='macro')\n",
    "\n",
    "x0 = np.asarray([1.0] * 4)  # 初始权重设为1\n",
    "lgb_res = optimize.fmin_powell(fun, x0)\n",
    "\n",
    "# 优化前后的性能对比\n",
    "xx_score = f1_score(df_train[LABEL], np.argmax(oof, axis=1), average='macro')\n",
    "print('阈值优化前:', xx_score)\n",
    "\n",
    "xx_cv = f1_score(df_train[LABEL], np.argmax(oof * lgb_res, axis=1), average='macro')\n",
    "print('阈值优化后:', xx_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已生成: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 生成最终提交文件\n",
    "submission = df_test[['新闻ID']].copy()\n",
    "submission['标签'] = np.argmax(test_preds * lgb_res, axis=1) + 1\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('提交文件已生成: submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 Macro F1-Score: 0.73445\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 Macro F1-Score: 0.75329\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 Macro F1-Score: 0.74658\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 Macro F1-Score: 0.74410\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 Macro F1-Score: 0.74296\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.761561\n",
      "         Iterations: 4\n",
      "         Function evaluations: 355\n",
      "阈值优化前: 0.7445221835327056\n",
      "阈值优化后: 0.7615611230384716\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "\n",
    "# 数据准备\n",
    "LABEL = '标签'\n",
    "feats = [f for f in data.columns if f not in [LABEL, '新闻ID', '文本']]\n",
    "df_train = data[~data[LABEL].isna()].copy()\n",
    "df_test = data[data[LABEL].isna()].copy()\n",
    "\n",
    "# 5折交叉验证\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# 存储每折的F1分数和预测结果\n",
    "scores = []\n",
    "oof = np.zeros((df_train.shape[0], 4))\n",
    "test_preds = np.zeros((df_test.shape[0], 4))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train[LABEL])):\n",
    "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "    X_train, X_val = df_train[feats].iloc[train_idx], df_train[feats].iloc[val_idx]\n",
    "    y_train, y_val = df_train[LABEL].iloc[train_idx], df_train[LABEL].iloc[val_idx]\n",
    "    \n",
    "    # 初始化 XGBoost 模型\n",
    "    model = XGBClassifier(\n",
    "        objective='multi:softprob',  # 多分类概率输出\n",
    "        num_class=4,                 # 类别数量\n",
    "        n_estimators=2000,           # 树的数量\n",
    "        learning_rate=0.05,          # 学习率\n",
    "        max_depth=7,                 # 最大深度\n",
    "        subsample=0.8,               # 子采样比例\n",
    "        colsample_bytree=0.8,        # 特征采样比例\n",
    "        random_state=42,\n",
    "        n_jobs=-1,                   # 并行线程数\n",
    "        verbosity=0                  # 静默模式\n",
    "    )\n",
    "    \n",
    "    # 模型训练\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 验证集预测\n",
    "    val_pred = model.predict_proba(X_val)\n",
    "    oof[val_idx] = val_pred\n",
    "    \n",
    "    # 计算 F1-score（宏平均）\n",
    "    score = f1_score(y_val, val_pred.argmax(-1), average='macro')\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {fold + 1} Macro F1-Score: {score:.5f}\")\n",
    "    \n",
    "    # 测试集预测\n",
    "    test_preds += model.predict_proba(df_test[feats]) / n_splits\n",
    "\n",
    "# 阈值优化\n",
    "def fun(x):\n",
    "    tmp = []\n",
    "    for i in range(4):\n",
    "        tmp.append(x[i] * oof[:, i].reshape(-1, 1))\n",
    "    tmp = np.hstack(tmp)\n",
    "    return -f1_score(df_train[LABEL].values, np.argmax(tmp, axis=1), average='macro')\n",
    "\n",
    "x0 = np.asarray([1.0] * 4)  # 初始权重设为1\n",
    "xgb_res = optimize.fmin_powell(fun, x0)\n",
    "\n",
    "# 优化前后的性能对比\n",
    "xx_score = f1_score(df_train[LABEL], np.argmax(oof, axis=1), average='macro')\n",
    "print('阈值优化前:', xx_score)\n",
    "\n",
    "xx_cv = f1_score(df_train[LABEL], np.argmax(oof * xgb_res, axis=1), average='macro')\n",
    "print('阈值优化后:', xx_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已生成: submission1.csv\n"
     ]
    }
   ],
   "source": [
    "submission1 = df_test[['新闻ID']].copy()\n",
    "submission1['标签'] = np.argmax(test_preds * xgb_res, axis=1) + 1\n",
    "submission1.to_csv('submission1.csv', index=False)\n",
    "print('提交文件已生成: submission1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
